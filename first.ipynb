{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab0bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# plus moderne que os\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c137c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"news-portal-user-interactions-by-globocom\")\n",
    "CLICK_DIR = DATA_DIR / \"clicks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a935776",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv(DATA_DIR / \"articles_metadata.csv\")\n",
    "\n",
    "with open(DATA_DIR / \"articles_embeddings.pickle\", \"rb\") as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "# Exclusion des articles vides\n",
    "mask_valid = articles[\"words_count\"] > 0\n",
    "articles_clean = articles[mask_valid].copy()\n",
    "embeddings_clean = embeddings[mask_valid.values]\n",
    "\n",
    "# Vérifs rapides\n",
    "assert len(articles_clean) == len(embeddings_clean)\n",
    "valid_ids = set(articles_clean[\"article_id\"].tolist())  # pour filtrer les clics\n",
    "# un set est optimisé en python pour vérifier a in A\n",
    "id_to_row = pd.Series(range(len(articles_clean)), index=articles_clean[\"article_id\"]).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9867338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24,\n",
       " [PosixPath('news-portal-user-interactions-by-globocom/clicks/clicks_hour_000.csv'),\n",
       "  PosixPath('news-portal-user-interactions-by-globocom/clicks/clicks_hour_001.csv'),\n",
       "  PosixPath('news-portal-user-interactions-by-globocom/clicks/clicks_hour_002.csv')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Liste des CSV de clics (ex: clicks_hour_000.csv, ...)\n",
    "all_click_files = sorted([p for p in CLICK_DIR.iterdir()])\n",
    "\n",
    "# ÉCHANTILLON: prends 24 premiers fichiers\n",
    "sample_files = all_click_files[:24]\n",
    "len(sample_files), sample_files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94ce62da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39218,\n",
       "    user_id  n_articles                   seen_articles  \\\n",
       " 0        0           2                 [68866, 157541]   \n",
       " 1        1           4  [235840, 160474, 59758, 96663]   \n",
       " 2        2           2                 [119592, 30970]   \n",
       " \n",
       "                                       profile_vector  \n",
       " 0  [-0.022445861, -0.9760792, -0.2589676, -0.0532...  \n",
       " 1  [-0.19884185, -0.96625423, -0.37118137, -0.048...  \n",
       " 2  [-0.7338902, -0.9666825, -0.12142117, -0.74176...  )"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Accumulateurs\n",
    "user_sum = defaultdict(lambda: np.zeros(embeddings_clean.shape[1], dtype=np.float32))  # somme des vecteurs\n",
    "user_cnt = defaultdict(int)                                                            # nombre d'articles pris en compte\n",
    "user_seen = defaultdict(set)                                                           # set des articles vus (pour filtrer + debug)\n",
    "\n",
    "# Boucle fichiers (lecture colonne minimale)\n",
    "usecols = [\"user_id\", \"click_article_id\"]\n",
    "\n",
    "for path in sample_files:\n",
    "    df = pd.read_csv(path, usecols=usecols)\n",
    "    # filtrer clics vers articles valides (non vides)\n",
    "    df = df[df[\"click_article_id\"].isin(valid_ids)]\n",
    "    if df.empty:\n",
    "        continue\n",
    "\n",
    "    # grouper par user → liste des articles cliqués\n",
    "    grouped = df.groupby(\"user_id\")[\"click_article_id\"].apply(list)\n",
    "    # en sortie on a un objet Series\n",
    "\n",
    "    for uid, art_list in grouped.items():\n",
    "        # supprimer doublons (un même article cliqué plusieurs fois dans l'heure)\n",
    "        unique_ids = set(art_list)\n",
    "        # mettre à jour le \"seen\"\n",
    "        user_seen[uid].update(unique_ids)\n",
    "\n",
    "        # sommer les vecteurs de ces articles\n",
    "        idxs = [id_to_row[aid] for aid in unique_ids if aid in id_to_row]  # robustesse\n",
    "        if not idxs:\n",
    "            continue\n",
    "        vecs = embeddings_clean[idxs]  # (n_i, 250)\n",
    "        user_sum[uid] += vecs.sum(axis=0)\n",
    "        user_cnt[uid] += len(idxs)\n",
    "\n",
    "# Construire le DataFrame des profils\n",
    "rows = []\n",
    "for uid, cnt in user_cnt.items():\n",
    "    if cnt == 0:\n",
    "        continue\n",
    "    mean_vec = (user_sum[uid] / cnt).astype(np.float32)  # moyenne\n",
    "    rows.append({\n",
    "        \"user_id\": uid,\n",
    "        \"n_articles\": cnt,\n",
    "        \"seen_articles\": list(user_seen[uid]),  # pour debug / filtrage plus tard\n",
    "        \"profile_vector\": mean_vec\n",
    "    })\n",
    "\n",
    "user_profiles = pd.DataFrame(rows)\n",
    "len(user_profiles), user_profiles.head(3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projet_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
